{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "# Using Reddit's API for Classifying Subreddit Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-23T19:28:02.619411Z",
     "start_time": "2017-10-23T19:28:02.600856Z"
    }
   },
   "source": [
    "In this project, we will practice two major skills. Collecting data via an API request and then building a binary predictor.\n",
    "\n",
    "As we discussed in week 2, and earlier today, there are two components to starting a data science problem: the problem statement, and acquiring the data.\n",
    "\n",
    "For this article, your problem statement will be: _What characteristics of a post on Reddit contribute most to what subreddit it belongs to?_\n",
    "\n",
    "Your method for acquiring the data will be scraping threads from at least two subreddits. \n",
    "\n",
    "Once you've got the data, you will build a classification model that, using Natural Language Processing and any other relevant features, predicts which subreddit a given post belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Imports\n",
    "\n",
    "# Regular data cleaning/handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# NLP specific libraries\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction import stop_words\n",
    "import re\n",
    "from string import punctuation\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "\n",
    "\n",
    "# Modeling Libraries\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using regular expressions to remove punctuation in a function\n",
    "def no_punct(string):\n",
    "    return re.sub(\"[.,ðŸ˜¯?ðŸ˜Š!â€™\\\";^+`:*'()-@â€â€œ=>_$&<~%|{}\\[\\]]\", \" \", string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to clean any column or to feed into the CountVectorizer as analyzer parameter\n",
    "def clean_func(column):\n",
    "    \n",
    "    #remove puntuation with punctuation removal function\n",
    "    column = no_punct(column)\n",
    "    \n",
    "    #lowercase\n",
    "    column = column.lower()\n",
    "    \n",
    "    #split string into just words\n",
    "    #column = column.split()\n",
    "    \n",
    "    return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the nlp lab\n",
    "\n",
    "def preprocess(text):\n",
    "    # instantiate lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # words only Regex, removes punctuation\n",
    "    text = re.sub(\"[^A-Za-z]\", \" \", text)\n",
    "    \n",
    "    # lemmatize\n",
    "    text = lemmatizer.lemmatize(text)\n",
    "    \n",
    "    # Take out stopwords\n",
    "    #text = [x for x in text.split() if not x in stopwords.words('english')]\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = pd.read_csv('./reddit_geocaching_posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can anyone advise me on how to log this multic...</td>\n",
       "      <td>Not sure how to log cache</td>\n",
       "      <td>geocaching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A quick Virtual Cache for the August Geochalle...</td>\n",
       "      <td>geocaching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I just bought a travel bug dog tag last week. ...</td>\n",
       "      <td>Copy Tag Question</td>\n",
       "      <td>geocaching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Logged my 300th find today! Atop Little Haysta...</td>\n",
       "      <td>geocaching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A neat set of mushrooms i saw on my caxhe hunt...</td>\n",
       "      <td>geocaching</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Can anyone advise me on how to log this multic...   \n",
       "1                                                NaN   \n",
       "2  I just bought a travel bug dog tag last week. ...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                               title   subreddit  \n",
       "0                          Not sure how to log cache  geocaching  \n",
       "1  A quick Virtual Cache for the August Geochalle...  geocaching  \n",
       "2                                  Copy Tag Question  geocaching  \n",
       "3  Logged my 300th find today! Atop Little Haysta...  geocaching  \n",
       "4  A neat set of mushrooms i saw on my caxhe hunt...  geocaching  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Is there a way to obtain a 30 day premium? My ...</td>\n",
       "      <td>30 day premium?</td>\n",
       "      <td>geocaching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Geocaching Adventure in North Texas!</td>\n",
       "      <td>geocaching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>What to do with this cache/s? (Poll)\\r\\r\\n\\r\\r...</td>\n",
       "      <td>What to do with this cache/s? (Poll)</td>\n",
       "      <td>geocaching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Iâ€™m wondering if Iâ€™m over doing it with plasti...</td>\n",
       "      <td>Plastic Bags</td>\n",
       "      <td>geocaching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>I found my spot and confirmed itâ€™s available, ...</td>\n",
       "      <td>Help: Hiding my first cache</td>\n",
       "      <td>geocaching</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "995  Is there a way to obtain a 30 day premium? My ...   \n",
       "996                                                NaN   \n",
       "997  What to do with this cache/s? (Poll)\\r\\r\\n\\r\\r...   \n",
       "998  Iâ€™m wondering if Iâ€™m over doing it with plasti...   \n",
       "999  I found my spot and confirmed itâ€™s available, ...   \n",
       "\n",
       "                                    title   subreddit  \n",
       "995                       30 day premium?  geocaching  \n",
       "996  Geocaching Adventure in North Texas!  geocaching  \n",
       "997  What to do with this cache/s? (Poll)  geocaching  \n",
       "998                          Plastic Bags  geocaching  \n",
       "999           Help: Hiding my first cache  geocaching  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>475</td>\n",
       "      <td>474</td>\n",
       "      <td>My mom and I have not \"found\" a cache with a 5...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>1000</td>\n",
       "      <td>999</td>\n",
       "      <td>5 Terrain</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>geocaching</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count unique                                                top  \\\n",
       "text        475    474  My mom and I have not \"found\" a cache with a 5...   \n",
       "title      1000    999                                          5 Terrain   \n",
       "subreddit  1000      1                                         geocaching   \n",
       "\n",
       "           freq  \n",
       "text          2  \n",
       "title         2  \n",
       "subreddit  1000  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to drop a duplicate\n",
    "geo_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         525\n",
       "title          0\n",
       "subreddit      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many nulls?\n",
    "geo_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaNs with NA\n",
    "geo_df.fillna('NA', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 3)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at length of title\n",
    "geo_title_length = geo_df['title'].map(clean_func)\n",
    "geo_title_length = geo_title_length.str.split()\n",
    "geo_title_length = geo_title_length.apply(len)\n",
    "\n",
    "# Plot it, is it significant?\n",
    "geo_title_length.plot(bins=50, kind='hist');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    999.000000\n",
       "mean       9.554555\n",
       "std        8.033421\n",
       "min        1.000000\n",
       "25%        4.000000\n",
       "50%        7.000000\n",
       "75%       12.000000\n",
       "max       62.000000\n",
       "Name: title, dtype: float64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_title_length.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostly distributed under 10 words but really skewed with a long tail. So there are only a few titles that are really long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at length of text\n",
    "geo_text_length = geo_df['text'].map(clean_func)\n",
    "geo_text_length = geo_text_length.str.split()\n",
    "geo_text_length = geo_text_length.apply(len)\n",
    "\n",
    "geo_text_length.plot(bins=50, kind='hist');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    999.000000\n",
       "mean      41.844845\n",
       "std       70.957119\n",
       "min        1.000000\n",
       "25%        1.000000\n",
       "50%        1.000000\n",
       "75%       61.000000\n",
       "max      612.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_text_length.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many posts have no text, or very short text bodies. But there is a much more longer skew with the tail on the right. Since text bodies can be longer, there are a few posts that are even longer than the longest titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring in IWantToLearn data for cleaning and exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "iwtl_df = pd.read_csv('./reddit_iwanttolearn_posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ever since I was young the thought of having t...</td>\n",
       "      <td>IWTL how to be okay with having to work for th...</td>\n",
       "      <td>IWantToLearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In case my dominant hand is damaged.</td>\n",
       "      <td>IWTL how to be ambidexter.</td>\n",
       "      <td>IWantToLearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>I want to learn how to experience music instea...</td>\n",
       "      <td>IWantToLearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi guys, are there any good courses, games or ...</td>\n",
       "      <td>IWTL how to improve my logical thinking and pr...</td>\n",
       "      <td>IWantToLearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have always wanted to own my own businesses,...</td>\n",
       "      <td>IWTL how to start a business - specifically a ...</td>\n",
       "      <td>IWantToLearn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Ever since I was young the thought of having t...   \n",
       "1               In case my dominant hand is damaged.   \n",
       "2                                                NaN   \n",
       "3  Hi guys, are there any good courses, games or ...   \n",
       "4  I have always wanted to own my own businesses,...   \n",
       "\n",
       "                                               title     subreddit  \n",
       "0  IWTL how to be okay with having to work for th...  IWantToLearn  \n",
       "1                         IWTL how to be ambidexter.  IWantToLearn  \n",
       "2  I want to learn how to experience music instea...  IWantToLearn  \n",
       "3  IWTL how to improve my logical thinking and pr...  IWantToLearn  \n",
       "4  IWTL how to start a business - specifically a ...  IWantToLearn  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iwtl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         108\n",
       "title          0\n",
       "subreddit      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iwtl_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping duplicates, and fill NaNs\n",
    "iwtl_df.drop_duplicates(inplace=True)\n",
    "iwtl_df.fillna('NA', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at length of title\n",
    "iwtl_title_length = iwtl_df['title'].map(clean_func)\n",
    "iwtl_title_length = iwtl_title_length.str.split()\n",
    "iwtl_title_length = iwtl_title_length.apply(len)\n",
    "\n",
    "# Plot it, is it significant?\n",
    "iwtl_title_length.plot(bins=50, kind='hist');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    996.000000\n",
       "mean       8.823293\n",
       "std        5.084502\n",
       "min        1.000000\n",
       "25%        6.000000\n",
       "50%        8.000000\n",
       "75%       10.000000\n",
       "max       61.000000\n",
       "Name: title, dtype: float64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iwtl_title_length.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at length of text\n",
    "iwtl_text_length = iwtl_df['text'].map(clean_func)\n",
    "iwtl_text_length = iwtl_text_length.str.split()\n",
    "iwtl_text_length = iwtl_text_length.apply(len)\n",
    "\n",
    "iwtl_text_length.plot(bins=50, kind='hist');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     996.000000\n",
       "mean       75.657631\n",
       "std        99.467357\n",
       "min         1.000000\n",
       "25%        27.000000\n",
       "50%        54.000000\n",
       "75%        92.000000\n",
       "max      1657.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iwtl_text_length.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a glance it looks like IWantToLearn titles and Geocaching titles are mostly distributed in less than 10 words. IWantToLearn posts have fewer \"title only\" type posts and tend to be longer than the geocaching posts that do have text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ever since I was young the thought of having t...</td>\n",
       "      <td>IWTL how to be okay with having to work for th...</td>\n",
       "      <td>IWantToLearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In case my dominant hand is damaged.</td>\n",
       "      <td>IWTL how to be ambidexter.</td>\n",
       "      <td>IWantToLearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NA</td>\n",
       "      <td>I want to learn how to experience music instea...</td>\n",
       "      <td>IWantToLearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi guys, are there any good courses, games or ...</td>\n",
       "      <td>IWTL how to improve my logical thinking and pr...</td>\n",
       "      <td>IWantToLearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have always wanted to own my own businesses,...</td>\n",
       "      <td>IWTL how to start a business - specifically a ...</td>\n",
       "      <td>IWantToLearn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Ever since I was young the thought of having t...   \n",
       "1               In case my dominant hand is damaged.   \n",
       "2                                                 NA   \n",
       "3  Hi guys, are there any good courses, games or ...   \n",
       "4  I have always wanted to own my own businesses,...   \n",
       "\n",
       "                                               title     subreddit  \n",
       "0  IWTL how to be okay with having to work for th...  IWantToLearn  \n",
       "1                         IWTL how to be ambidexter.  IWantToLearn  \n",
       "2  I want to learn how to experience music instea...  IWantToLearn  \n",
       "3  IWTL how to improve my logical thinking and pr...  IWantToLearn  \n",
       "4  IWTL how to start a business - specifically a ...  IWantToLearn  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that cleaning is correct\n",
    "iwtl_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Corpora\n",
    "\n",
    "Keep title and post text separate and create models from each separately. Later, I will explore whether combining both title and post text make a significant difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the corpus for titles\n",
    "title_corpus = pd.concat([geo_df['title'], iwtl_df['title']], axis=0, ignore_index=True)\n",
    "# type(title_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the corpus for text\n",
    "text_corpus = pd.concat([geo_df['text'], iwtl_df['text']], axis=0, ignore_index=True)\n",
    "# type(text_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "c7631f51-07f2-4c79-a093-3e9bc7849a48"
   },
   "source": [
    "#### We want to predict a binary variable - class `0` for one of your subreddits and `1` for the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the target column, change geocaching = 0, IWTL = 1\n",
    "y = pd.concat([geo_df['subreddit'], iwtl_df['subreddit']], axis=0, ignore_index=True)\n",
    "y = y.map({'geocaching': 0, 'IWantToLearn': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1990    â€‹EDIT: Specifically signal processing, I'd lik...\n",
       "1991    So that i have more money at the end of the mo...\n",
       "1992    And overcome my fear of presenting in front of...\n",
       "1993    Hello friends, today has been a very bad day f...\n",
       "1994    A friend of mine dared me to go mad for 1 week...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_corpus.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "db045898-1d2d-4af2-8e79-437c4c7546b4"
   },
   "source": [
    "## NLP\n",
    "\n",
    "#### Use `CountVectorizer` or `TfidfVectorizer` from scikit-learn to create features from the thread titles and descriptions (NOTE: Not all threads have a description)\n",
    "- Examine using count or binary features in the model\n",
    "- Re-evaluate your models using these. Does this improve the model performance? \n",
    "- What text features are the most valuable? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Master stopword list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a master stopword list from both stopword lists\n",
    "custom_stopwords = list(set(stopwords.words('english') + list(stop_words.ENGLISH_STOP_WORDS)))\n",
    "\n",
    "# Add 'na' because it indicates an empty text post\n",
    "custom_stopwords.extend(['na'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "379"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(custom_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a stopword list that only takes out 'na'\n",
    "no_na = ['na']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate CountVectorizer, leave as default but make sure 'na' isnt a feature\n",
    "cvec = CountVectorizer(stop_words=no_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_counts = cvec.fit_transform(title_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'not': 2201,\n",
       " 'sure': 3075,\n",
       " 'how': 1571,\n",
       " 'to': 3224,\n",
       " 'log': 1894,\n",
       " 'cache': 504,\n",
       " 'quick': 2560,\n",
       " 'virtual': 3413,\n",
       " 'for': 1262,\n",
       " 'the': 3169,\n",
       " 'august': 307,\n",
       " 'geochallenge': 1354,\n",
       " 'copy': 765,\n",
       " 'tag': 3106,\n",
       " 'question': 2558,\n",
       " 'logged': 1898,\n",
       " 'my': 2134,\n",
       " '300th': 44,\n",
       " 'find': 1213,\n",
       " 'today': 3226,\n",
       " 'atop': 292,\n",
       " 'little': 1876,\n",
       " 'haystack': 1501,\n",
       " 'nh': 2180,\n",
       " 'neat': 2158,\n",
       " 'set': 2805,\n",
       " 'of': 2225,\n",
       " 'mushrooms': 2129,\n",
       " 'saw': 2738,\n",
       " 'on': 2243,\n",
       " 'caxhe': 561,\n",
       " 'hunt': 1578,\n",
       " 'this': 3190,\n",
       " 'morning': 2098,\n",
       " 'spring': 2969,\n",
       " 'caching': 512,\n",
       " 'carnival': 545,\n",
       " 'geocaching': 1352,\n",
       " 'australia': 309,\n",
       " 'more': 2096,\n",
       " 'in': 1630,\n",
       " 'comments': 686,\n",
       " 'so': 2913,\n",
       " 'recently': 2606,\n",
       " 'started': 2983,\n",
       " 'new': 2174,\n",
       " 'thing': 3184,\n",
       " 'despite': 895,\n",
       " 'rain': 2571,\n",
       " 'falling': 1162,\n",
       " 'hurting': 1581,\n",
       " 'shoulder': 2836,\n",
       " 'and': 197,\n",
       " 'stabbing': 2974,\n",
       " 'inside': 1670,\n",
       " 'mouth': 2110,\n",
       " 'because': 368,\n",
       " 'was': 3451,\n",
       " 'stupid': 3044,\n",
       " 'enough': 1080,\n",
       " 'fall': 1161,\n",
       " 'face': 1154,\n",
       " 'first': 1227,\n",
       " 'with': 3529,\n",
       " 'pen': 2336,\n",
       " 'stick': 3001,\n",
       " 'almost': 167,\n",
       " 'eye': 1150,\n",
       " 'getting': 1374,\n",
       " 'bitten': 417,\n",
       " 'by': 500,\n",
       " 'ants': 218,\n",
       " 'it': 1719,\n",
       " 'great': 1428,\n",
       " 'weekend': 3480,\n",
       " 'found': 1269,\n",
       " 'woods': 3543,\n",
       " 'power': 2458,\n",
       " 'series': 2799,\n",
       " 'dorset': 978,\n",
       " 'uk': 3330,\n",
       " '82': 76,\n",
       " 'over': 2283,\n",
       " 'ten': 3149,\n",
       " 'hours': 1567,\n",
       " 'really': 2601,\n",
       " 'beautiful': 366,\n",
       " 'spot': 2965,\n",
       " 'at': 287,\n",
       " 'cliffs': 635,\n",
       " 'sydney': 3093,\n",
       " 'didn': 916,\n",
       " 'get': 1372,\n",
       " 'dangerous': 847,\n",
       " 'conditions': 725,\n",
       " 'bc': 359,\n",
       " 'just': 1764,\n",
       " 'rained': 2573,\n",
       " 'you': 3577,\n",
       " 'access': 96,\n",
       " 'passage': 2319,\n",
       " 'climbing': 638,\n",
       " 'up': 3357,\n",
       " 'ladder': 1800,\n",
       " 'rosa': 2691,\n",
       " 'gully': 1456,\n",
       " 'diamond': 912,\n",
       " 'bay': 358,\n",
       " 'things': 3185,\n",
       " 'wasn': 3455,\n",
       " 'even': 1107,\n",
       " 'near': 2156,\n",
       " 'watching': 3460,\n",
       " 'livepd': 1878,\n",
       " 'convinced': 756,\n",
       " 'drug': 1002,\n",
       " 'users': 3377,\n",
       " 'cars': 549,\n",
       " 'know': 1785,\n",
       " 'hide': 1525,\n",
       " 'coolest': 760,\n",
       " 'tree': 3282,\n",
       " 'mission': 2070,\n",
       " 'while': 3507,\n",
       " 'teaching': 3132,\n",
       " 'friend': 1282,\n",
       " 'events': 1109,\n",
       " 'will': 3517,\n",
       " 'attend': 296,\n",
       " 'being': 386,\n",
       " 'green': 1431,\n",
       " 'dashboard': 849,\n",
       " 'callendar': 521,\n",
       " 'is': 1713,\n",
       " 'limited': 1858,\n",
       " 'website': 3475,\n",
       " 'travel': 3274,\n",
       " 'bug': 483,\n",
       " 'making': 1961,\n",
       " 'our': 2279,\n",
       " 'geocache': 1346,\n",
       " 'completed': 701,\n",
       " 'closest': 642,\n",
       " 'geo': 1341,\n",
       " 'tour': 3243,\n",
       " 'fake': 1160,\n",
       " 'bomb': 437,\n",
       " 'boom': 442,\n",
       " 'note': 2203,\n",
       " 'box': 457,\n",
       " 'officers': 2231,\n",
       " 'suspect': 3080,\n",
       " 'linked': 1861,\n",
       " 'flux': 1251,\n",
       " 'capacitor': 537,\n",
       " 'geocoin': 1356,\n",
       " 'wierdest': 3513,\n",
       " 'stupidest': 3045,\n",
       " 'caches': 510,\n",
       " 've': 3391,\n",
       " 'ever': 1110,\n",
       " 'marker': 1979,\n",
       " 'yorkville': 3576,\n",
       " 'puts': 2546,\n",
       " 'spotlight': 2966,\n",
       " 'old': 2238,\n",
       " 'border': 446,\n",
       " 'illinois': 1607,\n",
       " 'beginner': 380,\n",
       " 'guide': 1451,\n",
       " 'what': 3497,\n",
       " 'do': 960,\n",
       " 'think': 3186,\n",
       " 'field': 1195,\n",
       " 'puzzles': 2550,\n",
       " 'that': 3168,\n",
       " 'are': 253,\n",
       " 'solved': 2923,\n",
       " 'simply': 2855,\n",
       " 'lots': 1925,\n",
       " 'trial': 3285,\n",
       " 'error': 1089,\n",
       " 'discover': 946,\n",
       " 'forest': 1263,\n",
       " 'request': 2645,\n",
       " 'free': 1275,\n",
       " 'trackable': 3252,\n",
       " 'com': 671,\n",
       " 'form': 1266,\n",
       " 'closes': 641,\n",
       " '29': 39,\n",
       " 'aug': 305,\n",
       " 'friends': 1284,\n",
       " 'league': 1821,\n",
       " 'souvenir': 2941,\n",
       " 'highest': 1531,\n",
       " 'count': 778,\n",
       " 'people': 2338,\n",
       " 'who': 3510,\n",
       " 'refuse': 2623,\n",
       " 'trails': 3266,\n",
       " 'naively': 2144,\n",
       " 'conceived': 714,\n",
       " 'down': 982,\n",
       " 'road': 2677,\n",
       " 'from': 1287,\n",
       " 'me': 1995,\n",
       " 'grab': 1416,\n",
       " 'bag': 335,\n",
       " 'worth': 3553,\n",
       " 'favourite': 1174,\n",
       " 'point': 2420,\n",
       " 'any': 221,\n",
       " 'good': 1405,\n",
       " 'way': 3465,\n",
       " 'have': 1496,\n",
       " 'multiple': 2125,\n",
       " 'incremental': 1642,\n",
       " 'hints': 1538,\n",
       " 'gentle': 1338,\n",
       " 'nudge': 2211,\n",
       " 'full': 1296,\n",
       " 'spoiler': 2960,\n",
       " 'listing': 1871,\n",
       " 'beginners': 381,\n",
       " 'here': 1520,\n",
       " 'one': 2245,\n",
       " 'has': 1490,\n",
       " 'tracking': 3255,\n",
       " 'trinkets': 3295,\n",
       " 'some': 2925,\n",
       " 'figures': 1199,\n",
       " 'pencils': 2337,\n",
       " 'stuff': 3040,\n",
       " 'we': 3468,\n",
       " 'take': 3109,\n",
       " 'trinket': 3294,\n",
       " 'leave': 1830,\n",
       " 'faster': 1169,\n",
       " 'easier': 1023,\n",
       " 'go': 1395,\n",
       " 'cross': 817,\n",
       " 'country': 784,\n",
       " 'instead': 1675,\n",
       " 'trail': 3265,\n",
       " 'other': 2276,\n",
       " 'lies': 1846,\n",
       " 'tell': 3144,\n",
       " 'myself': 2137,\n",
       " 'about': 87,\n",
       " 'interested': 1685,\n",
       " 'discord': 944,\n",
       " 'server': 2802,\n",
       " 'geocachers': 1350,\n",
       " 'day': 856,\n",
       " 'goal': 1396,\n",
       " 'accomplished': 102,\n",
       " 'texas': 3158,\n",
       " 'happy': 1484,\n",
       " 'international': 1688,\n",
       " 'or': 2260,\n",
       " 'an': 188,\n",
       " 'event': 1108,\n",
       " 'your': 3579,\n",
       " 'got': 1410,\n",
       " 'inspired': 1672,\n",
       " 'location': 1887,\n",
       " 'hid': 1523,\n",
       " 'decided': 869,\n",
       " 'make': 1959,\n",
       " 'portrait': 2443,\n",
       " 'imagine': 1613,\n",
       " 'all': 163,\n",
       " 'if': 1601,\n",
       " 'host': 1562,\n",
       " 'show': 2837,\n",
       " 'stumped': 3042,\n",
       " 'basically': 349,\n",
       " 'feel': 1182,\n",
       " 'like': 1856,\n",
       " 'failure': 1158,\n",
       " 'driving': 997,\n",
       " 'crazy': 800,\n",
       " 'local': 1883,\n",
       " 'media': 2004,\n",
       " 'crew': 811,\n",
       " 'made': 1946,\n",
       " 'video': 3405,\n",
       " 'promote': 2514,\n",
       " 'their': 3173,\n",
       " 'town': 3247,\n",
       " 'planted': 2392,\n",
       " 'puzzle': 2548,\n",
       " 'hope': 1559,\n",
       " 'ftf': 1293,\n",
       " 'appreciates': 242,\n",
       " 'views': 3410,\n",
       " '2018': 31,\n",
       " 'geocoinfest': 1357,\n",
       " 'gc7cx8f': 1320,\n",
       " 'after': 142,\n",
       " 'two': 3322,\n",
       " 'days': 857,\n",
       " 'miles': 2052,\n",
       " 'these': 3181,\n",
       " 'caught': 559,\n",
       " 'recent': 2605,\n",
       " 'asked': 273,\n",
       " 'wife': 3514,\n",
       " 'dinner': 930,\n",
       " 'going': 1399,\n",
       " 'she': 2818,\n",
       " 'laugh': 1816,\n",
       " 'as': 270,\n",
       " 'didnt': 917,\n",
       " 'see': 2779,\n",
       " 'behind': 385,\n",
       " 'gc31h5q': 1317,\n",
       " 'anyone': 224,\n",
       " 'hidden': 1524,\n",
       " 'significant': 2849,\n",
       " 'someone': 2928,\n",
       " 'claiming': 623,\n",
       " 'before': 378,\n",
       " 'published': 2532,\n",
       " 'world': 3551,\n",
       " 'turtle': 3315,\n",
       " 'real': 2595,\n",
       " 'life': 1847,\n",
       " 'try': 3306,\n",
       " 'again': 144,\n",
       " 'cashing': 553,\n",
       " 'escape': 1092,\n",
       " 'room': 2688,\n",
       " 'company': 693,\n",
       " 'hiding': 1528,\n",
       " 'texting': 3161,\n",
       " 'out': 2281,\n",
       " 'coordinates': 763,\n",
       " 'usually': 3379,\n",
       " 'located': 1885,\n",
       " 'exact': 1118,\n",
       " 'gps': 1412,\n",
       " 'photo': 2354,\n",
       " 'ccd3q4': 564,\n",
       " 'three': 3199,\n",
       " 'boxes': 458,\n",
       " 'tb': 3128,\n",
       " 'posted': 2449,\n",
       " 'screen': 2763,\n",
       " 'shot': 2834,\n",
       " 'op': 2252,\n",
       " 'fb': 1175,\n",
       " 'earlier': 1018,\n",
       " 'zoomed': 3592,\n",
       " 'searched': 2769,\n",
       " 'id': 1595,\n",
       " 'status': 2991,\n",
       " 'missing': 2069,\n",
       " 'omg': 2242,\n",
       " 'why': 3512,\n",
       " 'love': 1928,\n",
       " 'augusta': 308,\n",
       " 'very': 3399,\n",
       " 'don': 970,\n",
       " 'use': 3371,\n",
       " 'app': 232,\n",
       " 'could': 777,\n",
       " 'explain': 1138,\n",
       " 'would': 3554,\n",
       " 'help': 1514,\n",
       " 'much': 2118,\n",
       " 'thank': 3164,\n",
       " 'thought': 3193,\n",
       " 'does': 961,\n",
       " 'mean': 1998,\n",
       " 'cryptex': 824,\n",
       " 'images': 1611,\n",
       " 'description': 888,\n",
       " 'refound': 2621,\n",
       " 'years': 3570,\n",
       " 'later': 1811,\n",
       " 'singles': 2860,\n",
       " 'connector': 731,\n",
       " 'magnets': 1953,\n",
       " 'forst': 1267,\n",
       " 'time': 3214,\n",
       " 'using': 3378,\n",
       " 'doesnt': 963,\n",
       " 'let': 1840,\n",
       " 'page': 2299,\n",
       " 'google': 1408,\n",
       " 'code': 653,\n",
       " 'wood': 3539,\n",
       " 'awesome': 322,\n",
       " 'place': 2380,\n",
       " 'brought': 479,\n",
       " 'last': 1808,\n",
       " 'said': 2712,\n",
       " 'fill': 1203,\n",
       " 'mr': 2117,\n",
       " 'peackock': 2333,\n",
       " 'flag': 1236,\n",
       " 'counter': 780,\n",
       " 'extra': 1149,\n",
       " 'traceable': 3249,\n",
       " 'please': 2406,\n",
       " 'click': 634,\n",
       " 'treasurex': 3280,\n",
       " 'type': 3324,\n",
       " 'discussion': 949,\n",
       " 'trick': 3286,\n",
       " 'garmin': 1310,\n",
       " 'communicator': 692,\n",
       " 'osx': 2275,\n",
       " 'goodies': 1407,\n",
       " 'swag': 3083,\n",
       " 'st': 2973,\n",
       " 'john': 1749,\n",
       " 'newfoundland': 2177,\n",
       " 'quite': 2565,\n",
       " 'climb': 637,\n",
       " 'achieved': 108,\n",
       " 'finds': 1217,\n",
       " 'states': 2987,\n",
       " 'yesterday': 3574,\n",
       " 'hour': 1566,\n",
       " 'round': 2693,\n",
       " 'trip': 3296,\n",
       " 'turned': 3313,\n",
       " '12': 10,\n",
       " 'april': 246,\n",
       " 'fools': 1259,\n",
       " 'visit': 3416,\n",
       " 'grave': 1426,\n",
       " 'legendary': 1836,\n",
       " 'cacher': 507,\n",
       " 'amazing': 177,\n",
       " 'best': 396,\n",
       " 'midwest': 2049,\n",
       " 'locations': 1888,\n",
       " 'big': 404,\n",
       " 'animals': 203,\n",
       " 'come': 675,\n",
       " 'across': 110,\n",
       " 'offline': 2233,\n",
       " 'geooh': 1363,\n",
       " 'squibs': 2972,\n",
       " 'severed': 2809,\n",
       " 'foot': 1260,\n",
       " 'story': 3015,\n",
       " 'hawks': 1500,\n",
       " 'prarie': 2465,\n",
       " 'wa': 3432,\n",
       " 'aggressive': 148,\n",
       " 'unsporting': 3353,\n",
       " 'seekers': 2783,\n",
       " 'ideas': 1597,\n",
       " 'read': 2590,\n",
       " 'book': 440,\n",
       " 'official': 2232,\n",
       " 'works': 3550,\n",
       " 'well': 3490,\n",
       " 'am': 176,\n",
       " 'whale': 3496,\n",
       " 'waypoints': 3466,\n",
       " 'added': 120,\n",
       " 'visible': 3415,\n",
       " 'others': 2278,\n",
       " 'thoughts': 3194,\n",
       " 'lock': 1889,\n",
       " 'but': 495,\n",
       " 'gem': 1330,\n",
       " 'slightly': 2887,\n",
       " 'off': 2226,\n",
       " 'tiniest': 3218,\n",
       " 'far': 1167,\n",
       " 'sneakily': 2909,\n",
       " 'magnetised': 1951,\n",
       " 'underside': 3336,\n",
       " 'railing': 2569,\n",
       " 'park': 2309,\n",
       " 'kids': 1775,\n",
       " 'washington': 3454,\n",
       " 'state': 2986,\n",
       " 'couple': 785,\n",
       " 'questions': 2559,\n",
       " 'gonna': 1404,\n",
       " 'be': 360,\n",
       " 'sending': 2793,\n",
       " 'saturday': 2733,\n",
       " 'son': 2931,\n",
       " 'won': 3536,\n",
       " 'family': 1164,\n",
       " 'since': 2856,\n",
       " 'childhood': 602,\n",
       " 'lack': 1799,\n",
       " 'sad': 2708,\n",
       " 'stocking': 3005,\n",
       " 'newest': 2176,\n",
       " 'generation': 1333,\n",
       " 'young': 3578,\n",
       " 'cachers': 508,\n",
       " 'library': 1845,\n",
       " 'apps': 245,\n",
       " 'shoes': 2827,\n",
       " 'tips': 3221,\n",
       " 'classic': 626,\n",
       " 'twist': 3320,\n",
       " 'package': 2296,\n",
       " 'arrived': 262,\n",
       " 'ruined': 2700,\n",
       " 'year': 3569,\n",
       " 'rooster': 2690,\n",
       " 'groundspeak': 1439,\n",
       " 'throwing': 3204,\n",
       " 'towel': 3246,\n",
       " 'phone': 2352,\n",
       " 'mystery': 2140,\n",
       " 'treasure': 3278,\n",
       " 'came': 525,\n",
       " 'mail': 1955,\n",
       " 'creating': 803,\n",
       " 'creatures': 807,\n",
       " 'miniseries': 2064,\n",
       " 'own': 2289,\n",
       " 'fun': 1297,\n",
       " 'right': 2672,\n",
       " 'junior': 1763,\n",
       " 'his': 1540,\n",
       " 'owned': 2290,\n",
       " 'eastern': 1028,\n",
       " 'finland': 1223,\n",
       " 'owner': 2291,\n",
       " 'maintenance': 1958,\n",
       " 'brandenburg': 466,\n",
       " 'germany': 1371,\n",
       " 'hanger': 1479,\n",
       " 'scale': 2741,\n",
       " 'paperless': 2304,\n",
       " 'windows': 3522,\n",
       " 'firefox': 1225,\n",
       " 'dad': 843,\n",
       " 'went': 3491,\n",
       " 'island': 1714,\n",
       " 'hometown': 1553,\n",
       " 'paddle': 2298,\n",
       " 'check': 589,\n",
       " 'logs': 1904,\n",
       " 'used': 3372,\n",
       " 'back': 324,\n",
       " 'walk': 3438,\n",
       " 'guess': 1450,\n",
       " 'where': 3501,\n",
       " 'rules': 2703,\n",
       " 'logbook': 1895,\n",
       " 'although': 173,\n",
       " 'common': 688,\n",
       " 'excited': 1125,\n",
       " 'its': 1725,\n",
       " 'kind': 1778,\n",
       " 'terminus': 3152,\n",
       " 'twd': 3318,\n",
       " 'atlanta': 289,\n",
       " 'ga': 1301,\n",
       " '26': 38,\n",
       " 'homemade': 1551,\n",
       " 'items': 1722,\n",
       " 'gifts': 1380,\n",
       " 'including': 1635,\n",
       " 'specially': 2951,\n",
       " 'hosts': 1563,\n",
       " 'finally': 1209,\n",
       " 'finished': 1221,\n",
       " 'meet': 2009,\n",
       " 'area': 254,\n",
       " '1000': 5,\n",
       " 'pretty': 2476,\n",
       " '100': 4,\n",
       " 'can': 530,\n",
       " 'scripts': 2766,\n",
       " 'gpsmap': 1413,\n",
       " 'geocaches': 1351,\n",
       " 'geocacher': 1349,\n",
       " 'magazine': 1947,\n",
       " 'article': 265,\n",
       " 'name': 2145,\n",
       " 'blanked': 420,\n",
       " 'answering': 214,\n",
       " 'machine': 1942,\n",
       " 'when': 3500,\n",
       " 'cutting': 836,\n",
       " 'though': 3192,\n",
       " 'woodland': 3541,\n",
       " 'till': 3213,\n",
       " 'minutes': 2066,\n",
       " 'ago': 150,\n",
       " 'll': 1880,\n",
       " 'put': 2545,\n",
       " 'did': 915,\n",
       " 'into': 1696,\n",
       " 'sneaky': 2910,\n",
       " 'there': 3180,\n",
       " 'keywords': 1773,\n",
       " 'trigger': 3291,\n",
       " 'reviewer': 2665,\n",
       " 'attention': 297,\n",
       " 'pathtags': 2327,\n",
       " 'yaaaay': 3567,\n",
       " 'looking': 1915,\n",
       " 'unit': 3348,\n",
       " '2013june02_geocache_020': 28,\n",
       " 'coming': 682,\n",
       " 'too': 3234,\n",
       " 'exactly': 1119,\n",
       " 'drop': 998,\n",
       " 'ah': 152,\n",
       " 'yes': 3573,\n",
       " 'past': 2322,\n",
       " 'should': 2835,\n",
       " 'donate': 971,\n",
       " 'raffles': 2567,\n",
       " 'enjoy': 1078,\n",
       " 'receiving': 2604,\n",
       " 'gimmee': 1382,\n",
       " 'actually': 118,\n",
       " 'anymore': 223,\n",
       " 'submit': 3051,\n",
       " 'giff': 1378,\n",
       " 'terrain': 3153,\n",
       " 'spoilers': 2961,\n",
       " 'guys': 1459,\n",
       " 'sheet': 2819,\n",
       " 'roller': 2686,\n",
       " 'fishing': 1228,\n",
       " 'swivel': 3092,\n",
       " 'cotter': 776,\n",
       " 'pin': 2374,\n",
       " 'attempt': 295,\n",
       " 'possible': 2446,\n",
       " 'another': 212,\n",
       " 'different': 922,\n",
       " 'sized': 2869,\n",
       " 'parts': 2316,\n",
       " 'sister': 2863,\n",
       " 'mini': 2062,\n",
       " 'doing': 966,\n",
       " 'work': 3546,\n",
       " 'second': 2774,\n",
       " 'small': 2892,\n",
       " 'container': 746,\n",
       " 'bottom': 453,\n",
       " 'pipe': 2375,\n",
       " 'had': 1465,\n",
       " 'feed': 1180,\n",
       " 'sticks': 3002,\n",
       " 'through': 3201,\n",
       " 'hobby': 1545,\n",
       " 'introduce': 1698,\n",
       " 'saskatchewan': 2727,\n",
       " 'pirate': 2377,\n",
       " 'cranberry': 796,\n",
       " 'flats': 1238,\n",
       " 'geopup': 1364,\n",
       " 'sport': 2963,\n",
       " 'left': 1833,\n",
       " 'picked': 2364,\n",
       " 'arizona': 258,\n",
       " 'favorite': 1171,\n",
       " 'tiny': 3219,\n",
       " 'tied': 3209,\n",
       " 'string': 3025,\n",
       " 'pole': 2427,\n",
       " 'holding': 1548,\n",
       " 'sign': 2845,\n",
       " 'body': 434,\n",
       " 'released': 2631,\n",
       " 'albert': 157,\n",
       " 'lake': 1801,\n",
       " 'melbourne': 2016,\n",
       " 'post': 2448,\n",
       " 'posting': 2450,\n",
       " 'until': 3354,\n",
       " 'now': 2209,\n",
       " 'smallest': 2893,\n",
       " 'yet': 3575,\n",
       " 'somehow': 2927,\n",
       " 'easiest': 1024,\n",
       " 'woodlands': 3542,\n",
       " 'victoria': 3403,\n",
       " 'poem': 2417,\n",
       " 'electrical': 1054,\n",
       " 'charged': 581,\n",
       " 'gadget': 1302,\n",
       " 'trade': 3258,\n",
       " 'bluetooth': 432,\n",
       " 'receiver': 2603,\n",
       " 'nightcache': 2187,\n",
       " 'pocket': 2415,\n",
       " 'muggle': 2120,\n",
       " 'monsters': 2090,\n",
       " 'hoping': 1561,\n",
       " 'bunch': 487,\n",
       " 'bring': 473,\n",
       " 'along': 169,\n",
       " 'next': 2179,\n",
       " 'hunting': 1579,\n",
       " 'head': 1503,\n",
       " 'around': 259,\n",
       " 'portland': 2442,\n",
       " 'plain': 2386,\n",
       " 'sight': 2844,\n",
       " 'premium': 2470,\n",
       " 'membership': 2020,\n",
       " 'dnf': 958,\n",
       " 'tommy': 3229,\n",
       " 'few': 1190,\n",
       " 'weeks': 3483,\n",
       " 'pleased': 2407,\n",
       " 'pathtag': 2326,\n",
       " '1st': 24,\n",
       " '2nd': 41,\n",
       " 'wanted': 3446,\n",
       " 'share': 2814,\n",
       " 'play': 2399,\n",
       " 'wherigo': 3502,\n",
       " 'than': 3163,\n",
       " 'tattoo': 3123,\n",
       " 'boy': 460,\n",
       " 'comic': 681,\n",
       " 'month': 2092,\n",
       " 'lodi': 1893,\n",
       " 'latesvak': 1813,\n",
       " 'device': 906,\n",
       " 'working': 3548,\n",
       " 'stop': 3009,\n",
       " '916': 79,\n",
       " 'comment': 684,\n",
       " 'askhistorians': 274,\n",
       " 'thread': 3197,\n",
       " 'sub': 3048,\n",
       " 'might': 2050,\n",
       " 'regional': 2626,\n",
       " 'tests': 3157,\n",
       " 'end': 1069,\n",
       " 'canada': 531,\n",
       " 'zealand': 3586,\n",
       " 'sex': 2810,\n",
       " 'offender': 2227,\n",
       " 'arrested': 261,\n",
       " 'dirty': 936,\n",
       " 'willing': 3518,\n",
       " 'many': 1974,\n",
       " 'tenukko': 3150,\n",
       " 'ya': 3566,\n",
       " 'cool': 759,\n",
       " 'cleverly': 633,\n",
       " 'camoed': 528,\n",
       " 'something': 2929,\n",
       " 'urban': 3366,\n",
       " 'micros': 2046,\n",
       " 'solving': 2924,\n",
       " 'want': 3445,\n",
       " 'lost': 1923,\n",
       " 'dog': 964,\n",
       " 'competition': 696,\n",
       " 'brain': 463,\n",
       " 'damage': 844,\n",
       " 'huge': 1575,\n",
       " 'accomplishment': 103,\n",
       " 'challenges': 575,\n",
       " 'same': 2721,\n",
       " 'writing': 3559,\n",
       " 'nature': 2154,\n",
       " 'til': 3212,\n",
       " '1981': 20,\n",
       " 'titled': 3223,\n",
       " 'secret': 2775,\n",
       " 'associates': 282,\n",
       " 'riddles': 2669,\n",
       " 'pictures': 2370,\n",
       " 'usa': 3368,\n",
       " 'ceramic': 571,\n",
       " 'bin': 408,\n",
       " 'buried': 489,\n",
       " 'ground': 1437,\n",
       " 'houses': 1570,\n",
       " 'only': 2248,\n",
       " 'them': 3174,\n",
       " 'been': 374,\n",
       " 'vent': 3396,\n",
       " 'dispute': 953,\n",
       " 'judgement': 1759,\n",
       " 'whether': 3504,\n",
       " 'placement': 2383,\n",
       " 'fits': 1230,\n",
       " 'guidelines': 1452,\n",
       " 'involved': 1705,\n",
       " 'etch': 1100,\n",
       " 'sketch': 2873,\n",
       " 'stage': 2976,\n",
       " 'follow': 1255,\n",
       " 'instructions': 1676,\n",
       " 'need': 2160,\n",
       " 'water': 3461,\n",
       " 'special': 2950,\n",
       " 'tools': 3237,\n",
       " 'required': 2647,\n",
       " 'memorable': 2023,\n",
       " 'keep': 1766,\n",
       " 'natural': 2153,\n",
       " 'materials': 1989,\n",
       " 'camo': 527,\n",
       " 'attack': 294,\n",
       " 'amp': 187,\n",
       " 'become': 369,\n",
       " 'bear': 361,\n",
       " 'latest': 1812,\n",
       " 'quote': 2566,\n",
       " 'he': 1502,\n",
       " 'look': 1912,\n",
       " 'cute': 833,\n",
       " 'scary': 2747,\n",
       " 'scare': 2744,\n",
       " 'muggles': 2122,\n",
       " 'away': 321,\n",
       " 'crayfish': 798,\n",
       " 'micro': 2044,\n",
       " 'montana': 2091,\n",
       " 'pull': 2535,\n",
       " 'without': 3530,\n",
       " 'coords': 764,\n",
       " 'cell': 565,\n",
       " 'service': 2804,\n",
       " 'stopped': 3010,\n",
       " 'bet': 397,\n",
       " 'chance': 576,\n",
       " 'close': 640,\n",
       " 'example': 1121,\n",
       " 'finding': 1215,\n",
       " 'unexpected': 3342,\n",
       " 'pleasant': 2405,\n",
       " 'ending': 1070,\n",
       " 'combined': 674,\n",
       " 'sailing': 2714,\n",
       " 'passion': 2320,\n",
       " 'sailed': 2713,\n",
       " 'gorgeous': 1409,\n",
       " 'afternoon': 143,\n",
       " 'secured': 2777,\n",
       " 'stranger': 3017,\n",
       " 'grand': 1421,\n",
       " 'slam': 2882,\n",
       " 'seeeee': 2780,\n",
       " 'youu': 3583,\n",
       " 'signed': 2848,\n",
       " 'username': 3376,\n",
       " 'realize': 2598,\n",
       " 'idea': 1596,\n",
       " 'points': 2423,\n",
       " 'muggled': 2121,\n",
       " 'night': 2186,\n",
       " 'else': 1059,\n",
       " 'trying': 3307,\n",
       " 'under': 3335,\n",
       " 'malibu': 1965,\n",
       " 'having': 1498,\n",
       " 'mobile': 2077,\n",
       " 'site': 2865,\n",
       " 'info': 1657,\n",
       " 'placing': 2385,\n",
       " 'highly': 1533,\n",
       " 'recommend': 2609,\n",
       " 'handmade': 1475,\n",
       " 'smile': 2900,\n",
       " 'pics': 2368,\n",
       " 'ask': 272,\n",
       " 'below': 390,\n",
       " 'talk': 3114,\n",
       " 'crafts': 795,\n",
       " 'side': 2841,\n",
       " 'traik': 3264,\n",
       " 'complete': 700,\n",
       " 'satisfying': 2732,\n",
       " 'music': 2130,\n",
       " 'deleted': 878,\n",
       " 're': 2587,\n",
       " 'following': 1256,\n",
       " 'directions': 933,\n",
       " 'dude': 1009,\n",
       " 'adding': 123,\n",
       " 'everybody': 1112,\n",
       " 'feels': 1185,\n",
       " 'idiot': 1599,\n",
       " 'posts': 2451,\n",
       " 'checked': 590,\n",
       " 'map': 1975,\n",
       " 'gotta': 1411,\n",
       " 'ready': 2594,\n",
       " 'delorme': 879,\n",
       " 'pn': 2414,\n",
       " '60': 65,\n",
       " 'samsung': 2723,\n",
       " 'image': 1610,\n",
       " 'mad': 1945,\n",
       " 'river': 2675,\n",
       " 'ca': 502,\n",
       " 'monthly': 2093,\n",
       " 'july': 1761,\n",
       " 'entry': 1084,\n",
       " 'looks': 1917,\n",
       " 'lamp': 1802,\n",
       " 'skirt': 2880,\n",
       " 'title': 3222,\n",
       " 'bad': 332,\n",
       " 'medicine': 2006,\n",
       " 'geotalk': 1367,\n",
       " 'podcast': 2416,\n",
       " 'archive': 251,\n",
       " 'monday': 2087,\n",
       " '16': 13,\n",
       " '05': 2,\n",
       " 'pm': 2413,\n",
       " 'proposal': 2521,\n",
       " '7years': 74,\n",
       " 'most': 2101,\n",
       " 'amount': 186,\n",
       " 'times': 3216,\n",
       " 'listed': 1866,\n",
       " 'drive': 995,\n",
       " 'paris': 2308,\n",
       " 'region': 2625,\n",
       " 'driver': 996,\n",
       " 'logeur': 1897,\n",
       " '37pm': 50,\n",
       " '45': 59,\n",
       " '200': 26,\n",
       " 'kilometers': 1777,\n",
       " 'cutworm': 837,\n",
       " 'station': 2988,\n",
       " 'cz': 841,\n",
       " 'longest': 1910,\n",
       " 'gap': 1307,\n",
       " 'between': 399,\n",
       " 'seen': 2787,\n",
       " 'scared': 2745,\n",
       " 'always': 174,\n",
       " 'crack': 794,\n",
       " 'may': 1993,\n",
       " 'accidental': 99,\n",
       " 'stumbled': 3041,\n",
       " 'upon': 3364,\n",
       " 'weeki': 3481,\n",
       " 'mermaid': 2031,\n",
       " 'art': 264,\n",
       " 'mÃ¶lnbo': 2142,\n",
       " 'sweden': 3087,\n",
       " 'gooderham': 1406,\n",
       " 'ontario': 2249,\n",
       " '23': 36,\n",
       " '15th': 12,\n",
       " 'biggest': 405,\n",
       " 'haul': 1494,\n",
       " 'webcam': 3473,\n",
       " 'wish': 3527,\n",
       " 'they': 3182,\n",
       " 'were': 3492,\n",
       " 'starting': 2985,\n",
       " 'hard': 1486,\n",
       " 'top': 3238,\n",
       " 'coin': 657,\n",
       " 'anybody': 222,\n",
       " 'upgraded': 3361,\n",
       " 'movie': 2113,\n",
       " 'lovely': 1930,\n",
       " 'explore': 1143,\n",
       " 'cleaning': 630,\n",
       " 'nano': 2148,\n",
       " 'tweezers': 3319,\n",
       " 'misplaced': 2067,\n",
       " 'rolled': 2685,\n",
       " 'probably': 2489,\n",
       " 'date': 852,\n",
       " 'suggestions': 3062,\n",
       " 'goals': 1397,\n",
       " 'query': 2556,\n",
       " 'girlfriend': 1384,\n",
       " 'took': 3235,\n",
       " 'each': 1015,\n",
       " 't5': 3103,\n",
       " 'treeclimbing': 3283,\n",
       " 'gears': 1328,\n",
       " 'snapcaching': 2905,\n",
       " 'snapchat': 2906,\n",
       " 'instagram': 1673,\n",
       " 'adventures': 133,\n",
       " 'containers': 747,\n",
       " 'nice': 2181,\n",
       " 'hike': 1534,\n",
       " 'northern': 2198,\n",
       " ...}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = pd.DataFrame(title_counts.todense(), columns=cvec.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "light           1221\n",
       "nnamdi           767\n",
       "mgs              748\n",
       "skilled          396\n",
       "people           337\n",
       "hooked           315\n",
       "negative         277\n",
       "affect           221\n",
       "touches          187\n",
       "apps             181\n",
       "prague           158\n",
       "ice              137\n",
       "ci               135\n",
       "makes            128\n",
       "hand             123\n",
       "glad             123\n",
       "why              123\n",
       "commitments      116\n",
       "outside          112\n",
       "meal             111\n",
       "crisis           109\n",
       "cheeseburger     104\n",
       "ammo              94\n",
       "gz                88\n",
       "spot              87\n",
       "bridge            79\n",
       "form              75\n",
       "national          72\n",
       "15th              68\n",
       "specifically      67\n",
       "                ... \n",
       "revenge            1\n",
       "impressively       1\n",
       "seeing             1\n",
       "reputation         1\n",
       "gets               1\n",
       "wall               1\n",
       "dead               1\n",
       "walking            1\n",
       "jobs               1\n",
       "litter             1\n",
       "constructed        1\n",
       "stealth            1\n",
       "cam                1\n",
       "gcae               1\n",
       "hollow             1\n",
       "late               1\n",
       "lucille            1\n",
       "lucy               1\n",
       "hockey             1\n",
       "contact            1\n",
       "accounts           1\n",
       "lunch              1\n",
       "social             1\n",
       "chickadee          1\n",
       "consecutive        1\n",
       "reaction           1\n",
       "multicache         1\n",
       "shocked            1\n",
       "denton             1\n",
       "riiiiiiick         1\n",
       "Length: 3593, dtype: int64"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_counts = cvec.fit_transform(text_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts2 = pd.DataFrame(text_counts.todense(), columns=cvec.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>can</th>\n",
       "      <th>anyone</th>\n",
       "      <th>advise</th>\n",
       "      <th>me</th>\n",
       "      <th>on</th>\n",
       "      <th>how</th>\n",
       "      <th>to</th>\n",
       "      <th>log</th>\n",
       "      <th>this</th>\n",
       "      <th>multicache</th>\n",
       "      <th>...</th>\n",
       "      <th>palettes</th>\n",
       "      <th>unused</th>\n",
       "      <th>lights</th>\n",
       "      <th>quizzes</th>\n",
       "      <th>68</th>\n",
       "      <th>rewarded</th>\n",
       "      <th>geniuses</th>\n",
       "      <th>80s</th>\n",
       "      <th>70s</th>\n",
       "      <th>dared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1995 rows Ã— 8690 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      can  anyone  advise  me  on  how  to  log  this  multicache  ...    \\\n",
       "0       0       0       0   0   0    0   0    0     0           0  ...     \n",
       "1       0       0       0   0   0    0   0    0     0           0  ...     \n",
       "2       0       0       0   0   0    0   0    0     0           0  ...     \n",
       "3       0       0       0   0   0    0   0    0     0           0  ...     \n",
       "4       0       0       0   0   0    0   0    0     0           0  ...     \n",
       "5       0       0       0   0   0    0   0    0     0           0  ...     \n",
       "6       0       0       0   0   0    0   0    0     0           0  ...     \n",
       "7       0       0       0   0   0    0   0    0     0           0  ...     \n",
       "8       0       0       0   0   0    0   0    0     0           0  ...     \n",
       "9       0       0       0   0   0    0   0    0     0           0  ...     \n",
       "10      0       0       0   0   0    0   0    0     0           0  ...     \n",
       "11      0       0       0   0   0    0   0    0     0           0  ...     \n",
       "12      0       0       0   0   0    0   0    0     0           0  ...     \n",
       "13      0       0       0   0   0    0   0    0     0           0  ...     \n",
       "14      0       0       0   0   0    0   0    0     0           0  ...     \n",
       "15      0       0       0   0   0    0   0    0     0           0  ...     \n",
       "16      0       0       0   0   0    0   0    0     0           0  ...     \n",
       "17      0       0       0   0   0    0   0    0     0           0  ...     \n",
       "18      0       0       0   0   0    0   0    0     0           0  ...     \n",
       "19      0       0       0   0   0    0   0    0     0           0  ...     \n",
       "20      0       0       0   0   0    0   0    0     0           0  ...     \n",
       "21      0       0       0   0   0    0   0    0     0           0  ...     \n",
       "22      0       0       0   0   0    0   0    0     0           0  ...     \n",
       "23      0       0       0   0   0    0   0    1     0           0  ...     \n",
       "24      0       0       0   0   0    0   0    0     0           0  ...     \n",
       "25      0       0       0   0   0    0   0    0     0           0  ...     \n",
       "26      0       0       0   0   0    0   0    1     0           0  ...     \n",
       "27      0       0       0   0   0    0   0    0     0           0  ...     \n",
       "28      0       0       0   0   0    0   0    0     0           0  ...     \n",
       "29      0       0       0   0   0    0   0    0     0           0  ...     \n",
       "...   ...     ...     ...  ..  ..  ...  ..  ...   ...         ...  ...     \n",
       "1965    0       0       0   0   0    0   0    0     0           0  ...     \n",
       "1966    0       0       0   0   0    0   0    0     0           0  ...     \n",
       "1967    0       0       0   0   0    0   0    0     0           0  ...     \n",
       "1968    0       0       0   0   0    0   1    0     0           0  ...     \n",
       "1969    0       0       0   0   0    0   0    0     0           0  ...     \n",
       "1970    0       0       0   0   0    0   0    0     0           0  ...     \n",
       "1971    0       0       0   0   0    0   0    0     0           0  ...     \n",
       "1972    0       0       0   0   0    0   0    0     0           0  ...     \n",
       "1973    0       0       0   0   0    0   1    0     0           0  ...     \n",
       "1974    0       0       0   0   0    0   0    0     0           0  ...     \n",
       "1975    0       0       0   0   0    0   0    0     0           0  ...     \n",
       "1976    0       0       0   0   0    0   0    0     0           0  ...     \n",
       "1977    0       0       0   0   0    0   0    0     0           0  ...     \n",
       "1978    0       0       0   0   0    0   0    0     0           0  ...     \n",
       "1979    0       0       0   0   0    0   0    0     0           0  ...     \n",
       "1980    0       0       0   0   0    0   0    0     0           0  ...     \n",
       "1981    0       0       0   0   0    0   1    0     0           0  ...     \n",
       "1982    0       0       0   0   0    0   0    0     0           0  ...     \n",
       "1983    0       0       0   0   0    0   0    0     0           0  ...     \n",
       "1984    0       0       0   0   0    0   0    0     0           0  ...     \n",
       "1985    0       0       0   0   0    0   0    0     0           0  ...     \n",
       "1986    0       0       0   0   0    0   0    0     0           0  ...     \n",
       "1987    0       0       0   0   0    0   0    0     0           0  ...     \n",
       "1988    0       0       0   0   0    0   0    0     0           0  ...     \n",
       "1989    0       0       0   0   0    0   0    0     0           0  ...     \n",
       "1990    0       0       0   0   0    0   0    0     0           0  ...     \n",
       "1991    0       0       0   0   0    0   0    0     0           0  ...     \n",
       "1992    0       0       0   0   0    0   0    0     0           0  ...     \n",
       "1993    0       0       0   0   0    0   0    1     0           0  ...     \n",
       "1994    0       0       0   0   0    0   0    0     0           0  ...     \n",
       "\n",
       "      palettes  unused  lights  quizzes  68  rewarded  geniuses  80s  70s  \\\n",
       "0            0       0       0        0   0         0         0    0    0   \n",
       "1            0       0       0        0   0         0         0    0    0   \n",
       "2            0       0       0        0   0         0         0    0    0   \n",
       "3            0       0       0        0   0         0         0    0    0   \n",
       "4            0       0       0        0   0         0         0    0    0   \n",
       "5            0       0       0        0   0         0         0    0    0   \n",
       "6            0       0       0        0   0         0         0    0    0   \n",
       "7            0       0       0        0   0         0         0    0    0   \n",
       "8            0       0       0        0   0         0         0    0    0   \n",
       "9            0       0       0        0   0         0         0    0    0   \n",
       "10           0       0       0        0   0         0         0    0    0   \n",
       "11           0       0       0        0   0         0         0    0    0   \n",
       "12           0       0       0        0   0         0         0    0    0   \n",
       "13           0       0       0        0   0         0         0    0    0   \n",
       "14           0       0       0        0   0         0         0    0    0   \n",
       "15           0       0       0        0   0         0         0    0    0   \n",
       "16           0       0       0        0   0         0         0    0    0   \n",
       "17           0       0       0        0   0         0         0    0    0   \n",
       "18           0       0       0        0   0         0         0    0    0   \n",
       "19           0       0       0        0   0         0         0    0    0   \n",
       "20           0       0       0        0   0         0         0    0    0   \n",
       "21           0       0       0        0   0         0         0    0    0   \n",
       "22           0       0       0        0   0         0         0    0    0   \n",
       "23           0       0       0        0   0         0         0    0    0   \n",
       "24           0       0       0        0   0         0         0    0    0   \n",
       "25           0       0       0        0   0         0         0    0    0   \n",
       "26           0       0       0        0   0         0         0    0    0   \n",
       "27           0       0       0        0   0         0         0    0    0   \n",
       "28           0       0       0        0   0         0         0    0    0   \n",
       "29           0       0       0        0   0         0         0    0    0   \n",
       "...        ...     ...     ...      ...  ..       ...       ...  ...  ...   \n",
       "1965         0       0       0        0   0         0         0    0    0   \n",
       "1966         0       0       0        0   0         0         0    0    0   \n",
       "1967         0       0       1        0   0         0         0    0    0   \n",
       "1968         0       0       0        0   0         0         0    0    0   \n",
       "1969         0       0       0        0   0         0         0    0    0   \n",
       "1970         0       0       0        0   0         0         0    0    0   \n",
       "1971         0       0       0        0   0         0         0    0    0   \n",
       "1972         0       0       0        0   0         0         0    0    0   \n",
       "1973         0       0       0        0   0         0         0    0    0   \n",
       "1974         0       0       0        0   0         0         0    0    0   \n",
       "1975         0       0       0        0   0         0         0    0    0   \n",
       "1976         0       0       0        0   0         0         0    0    0   \n",
       "1977         0       0       0        0   0         0         0    0    0   \n",
       "1978         0       0       0        0   0         0         0    0    0   \n",
       "1979         0       0       0        0   0         0         0    0    0   \n",
       "1980         0       0       0        0   0         0         0    0    0   \n",
       "1981         0       0       0        0   0         0         0    0    0   \n",
       "1982         0       0       0        0   0         0         0    0    0   \n",
       "1983         0       0       0        0   0         0         0    0    0   \n",
       "1984         0       0       0        0   0         0         0    0    0   \n",
       "1985         0       0       0        0   0         0         0    0    0   \n",
       "1986         0       0       0        0   0         0         0    0    0   \n",
       "1987         0       0       0        0   0         0         0    0    0   \n",
       "1988         0       0       0        0   0         0         0    0    0   \n",
       "1989         0       0       0        0   0         0         0    0    0   \n",
       "1990         0       0       0        0   0         0         0    0    0   \n",
       "1991         0       0       0        0   0         0         0    0    0   \n",
       "1992         0       0       0        0   0         0         0    0    0   \n",
       "1993         0       0       0        0   0         0         0    0    0   \n",
       "1994         0       0       0        0   0         0         0    0    0   \n",
       "\n",
       "      dared  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "5         0  \n",
       "6         0  \n",
       "7         0  \n",
       "8         0  \n",
       "9         0  \n",
       "10        0  \n",
       "11        0  \n",
       "12        0  \n",
       "13        0  \n",
       "14        0  \n",
       "15        0  \n",
       "16        0  \n",
       "17        0  \n",
       "18        0  \n",
       "19        0  \n",
       "20        0  \n",
       "21        0  \n",
       "22        0  \n",
       "23        0  \n",
       "24        0  \n",
       "25        0  \n",
       "26        0  \n",
       "27        0  \n",
       "28        0  \n",
       "29        0  \n",
       "...     ...  \n",
       "1965      0  \n",
       "1966      0  \n",
       "1967      0  \n",
       "1968      0  \n",
       "1969      0  \n",
       "1970      0  \n",
       "1971      0  \n",
       "1972      0  \n",
       "1973      0  \n",
       "1974      0  \n",
       "1975      0  \n",
       "1976      0  \n",
       "1977      0  \n",
       "1978      0  \n",
       "1979      0  \n",
       "1980      0  \n",
       "1981      0  \n",
       "1982      0  \n",
       "1983      0  \n",
       "1984      0  \n",
       "1985      0  \n",
       "1986      0  \n",
       "1987      0  \n",
       "1988      0  \n",
       "1989      0  \n",
       "1990      0  \n",
       "1991      0  \n",
       "1992      0  \n",
       "1993      0  \n",
       "1994      0  \n",
       "\n",
       "[1995 rows x 8690 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "animate             4387\n",
       "colors              3218\n",
       "decide              3178\n",
       "markers             1801\n",
       "scared              1730\n",
       "living              1535\n",
       "3d                  1506\n",
       "wash                1348\n",
       "lampworker          1176\n",
       "sodakzaks_circle    1101\n",
       "artwork             1087\n",
       "possibility         1067\n",
       "lie                  813\n",
       "proprietorship       781\n",
       "arrange              775\n",
       "flawed               769\n",
       "ghosts               758\n",
       "volatile             745\n",
       "upside               705\n",
       "murder               691\n",
       "5s                   691\n",
       "letting              691\n",
       "enjoys               676\n",
       "gc7qqk3              649\n",
       "bump                 601\n",
       "thread               587\n",
       "banks                571\n",
       "valerian             510\n",
       "wings                510\n",
       "sometimes            504\n",
       "                    ... \n",
       "32                     1\n",
       "conducting             1\n",
       "conducted              1\n",
       "financial              1\n",
       "deteriorating          1\n",
       "improved               1\n",
       "piano                  1\n",
       "achieve                1\n",
       "feminine               1\n",
       "products               1\n",
       "relatives              1\n",
       "shakiness              1\n",
       "unsure                 1\n",
       "tension                1\n",
       "throat                 1\n",
       "weak                   1\n",
       "drawers                1\n",
       "bass                   1\n",
       "repairing              1\n",
       "phrase                 1\n",
       "reached                1\n",
       "barrier                1\n",
       "costing                1\n",
       "overweight             1\n",
       "weight                 1\n",
       "pounds                 1\n",
       "admire                 1\n",
       "gaga                   1\n",
       "woman                  1\n",
       "hopelessness           1\n",
       "Length: 8690, dtype: int64"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts2.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_counts = pd.concat([counts, counts2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1995, 12283)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1995,)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On the Training Title Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit cvec to our title corpus\n",
    "title_fit = cvec.fit(X_train_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3045"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title_fit.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length: 7433\n",
      "Longest word: medieval_fantasy_city_generator_by_oleg_dolya\n"
     ]
    }
   ],
   "source": [
    "title_vocab = title_fit.vocabulary_\n",
    "\n",
    "print('Vocabulary length:', len(title_fit.get_feature_names()))\n",
    "print('Longest word:', max(title_vocab, key=len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like bare-bones CountVectorizer isn't enough. Additional parameters need to be set to pare down the vocabulary. Assume the same will be true of the training text corpus as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use GridSearchCV with Pipeline to optimize CountVectorizer/TfidfVectorizer and a Multinomial NB classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer()\n",
    "split = train_test_split()\n",
    "model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'cvec__stop_words': [no_na, 'english'],\n",
    "    'cvec__analyzer': ['word', preprocess],\n",
    "    'cvec__ngram_range': [(1,1), (1, 2)],\n",
    "    'split__random_state': [42],\n",
    "    'split__test_size': [0.3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('cvec', cvec),  #countvectorizer\n",
    "    ('split', split)\n",
    "    ('model', model) #classifier model\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('cvec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor...zer=None, vocabulary=None)), ('model', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'cvec__stop_words': [['na'], 'english'], 'cvec__analyzer': ['word', <function preprocess at 0x011768E8>], 'cvec__ngram_range': [(1, 1), (1, 2)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(pipeline, param_grid=params, cv=5)\n",
    "gs.fit(,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cvec__analyzer': 'word', 'cvec__ngram_range': (1, 1), 'cvec__stop_words': ['na']}\n",
      "0.9659090909090909\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_params_)\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline parameters and score for CountVectorizer()\n",
    "\n",
    "Best params:\n",
    "\n",
    "`{'cvec__analyzer': 'word', 'cvec__max_features': None, 'cvec__stop_words': ['na']}`\n",
    "\n",
    "Best score:\n",
    "\n",
    "0.9719298245614035"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On the Training Text Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_fit = cvec.fit(X_train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7433"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_fit.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length: 3045\n",
      "Longest word: 2013june02_geocache_020\n"
     ]
    }
   ],
   "source": [
    "text_vocab = text_fit.vocabulary_\n",
    "\n",
    "print('Vocabulary length:', len(text_fit.get_feature_names()))\n",
    "print('Longest word:', max(text_vocab, key=len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate, leave as default\n",
    "tfidf = TfidfVectorizer(stop_words=no_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit to title corpus\n",
    "title_fit_tf = tfidf.fit(title_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3593"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title_fit_tf.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No change in number of features by using TF-IDF on titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_fit_tf = tfidf.fit(text_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8690"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_fit_tf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length: 8690\n",
      "Longest word: medieval_fantasy_city_generator_by_oleg_dolya\n"
     ]
    }
   ],
   "source": [
    "text_tf_vocab = text_fit_tf.vocabulary_\n",
    "# text_vocab\n",
    "\n",
    "print('Vocabulary length:', len(text_fit_tf.get_feature_names()))\n",
    "print('Longest word:', max(text_tf_vocab, key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the words that TF-IDF kept\n",
    "[word for word in text_fit_tf.vocabulary_ if word not in text_fit.vocabulary_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec = TfidfVectorizer()\n",
    "model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),  #TF-IDF\n",
    "    ('model', model) #classifier model\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_params = {\n",
    "    'tvec__stop_words': [no_na, 'english'],\n",
    "    'tvec__preprocessor': [preprocess],\n",
    "    'tvec__max_df': [500, 1000, 1500],\n",
    "    'tvec__min_df': [1, 2, 3],\n",
    "    'tvec__ngram_range': [(1, 1), (1, 3)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('tvec', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "  ...e,\n",
       "        vocabulary=None)), ('model', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'tvec__stop_words': [['na'], 'english'], 'tvec__preprocessor': [<function preprocess at 0x011768E8>], 'tvec__max_df': [500, 1000, 1500], 'tvec__min_df': [1, 2, 3], 'tvec__ngram_range': [(1, 1), (1, 3)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(pipeline, param_grid=t_params, cv=5)\n",
    "gs.fit(title_corpus, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tvec__max_df': 1000,\n",
       " 'tvec__min_df': 1,\n",
       " 'tvec__ngram_range': (1, 1),\n",
       " 'tvec__preprocessor': <function __main__.preprocess(text)>,\n",
       " 'tvec__stop_words': ['na']}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9639097744360903"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer()\n",
    "tvec = TfidfVectorizer()\n",
    "model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('cvec', CountVectorizer()),  #countvectorizer\n",
    "    ('tvec', TfidfVectorizer()),  #TF-IDF\n",
    "    ('model', model) #classifier model\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'cvec__stop_words': [no_na, 'english', custom_stopwords],\n",
    "    'cvec__analyzer': ['word'],\n",
    "    'tvec__lowercase': [False],\n",
    "    'tvec__max_df': [500, 750, 1000],\n",
    "    'tvec__min_df': [1, 2, 3],\n",
    "    'tvec__ngram_range': [(1, 1), (1, 3)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-153-6f1ef7340f65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_title\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \"\"\"\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    211\u001b[0m                 Xt, fitted_transformer = fit_transform_one_cached(\n\u001b[0;32m    212\u001b[0m                     \u001b[0mcloned_transformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m                     **fit_params_steps[name])\n\u001b[0m\u001b[0;32m    214\u001b[0m                 \u001b[1;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                 \u001b[1;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, weight, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m                        **fit_params):\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1379\u001b[0m             \u001b[0mTf\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0midf\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mweighted\u001b[0m \u001b[0mdocument\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mterm\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1380\u001b[0m         \"\"\"\n\u001b[1;32m-> 1381\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1382\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m         \u001b[1;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[1;32m--> 869\u001b[1;33m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[0;32m    870\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    871\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 792\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    793\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[1;32m--> 266\u001b[1;33m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m    239\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[0mtoken_pattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoken_pattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtoken_pattern\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_stop_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "gs = GridSearchCV(pipeline, param_grid=params, cv=5)\n",
    "gs.fit(X_train_title, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9632352941176471"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best score 0.965"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__analyzer': <function __main__.clean_func(column)>,\n",
       " 'cvec__stop_words': 'english'}"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best params for best score: \n",
    "\n",
    "`{'cvec__analyzer': <function __main__.clean_func(column)>,\n",
    " 'cvec__stop_words': 'english'}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9739478957915831"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test_title, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best score 0.973"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea: Have separate branch where combine Title and Post Text then run count vectorizer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = geo_df['text'] + ' ' + geo_df['title']\n",
    "iwtl = iwtl_df['text'] + ' ' + iwtl_df['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.concat([geo, iwtl], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Can anyone advise me on how to log this multic...\n",
       "1    NA A quick Virtual Cache for the August Geocha...\n",
       "2    I just bought a travel bug dog tag last week. ...\n",
       "3    NA Logged my 300th find today! Atop Little Hay...\n",
       "4    NA A neat set of mushrooms i saw on my caxhe h...\n",
       "dtype: object"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "04563b69-f7b6-466f-9d65-fc62c9ddee6a"
   },
   "source": [
    "## Predicting subreddit using Random Forests + Another Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "588f9845-6143-4bcc-bfd1-85d45b79303d"
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "\n",
    "rf.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "c20d2498-151c-44c3-a453-3a333c79a0ac"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a7afb2c0-d41e-4779-8216-91cd8dd4473f"
   },
   "source": [
    "#### Thought experiment: What is the baseline accuracy for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "87a17d3d-b7f4-4747-9f75-f9af1d18a174"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "4fb29de2-5b98-474c-a4ad-5170b72b9aea"
   },
   "source": [
    "#### Create a `RandomForestClassifier` model to predict which subreddit a given post belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "ddbc6159-6854-4ca7-857f-bfecdaf6d9c2"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9367beff-72ba-4768-a0ba-a50b335de61d"
   },
   "source": [
    "#### Use cross-validation in scikit-learn to evaluate the model above. \n",
    "- Evaluate the accuracy of the model, as well as any other metrics you feel are appropriate. \n",
    "- **Bonus**: Use `GridSearchCV` with `Pipeline` to optimize your `CountVectorizer`/`TfidfVectorizer` and classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "269b9e7c-60b5-4a06-8255-881d7395bc1b"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('cvec', CountVectorizer())  #countvectorizer\n",
    "    ('tvec', TfidfVectorizer())  #TF-IDF\n",
    "    ('model', ) #classifier model\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(pipeline, param_grid={})\n",
    "gs.fit(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat the model-building process using a different classifier (e.g. `MultinomialNB`, `LogisticRegression`, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executive Summary\n",
    "---\n",
    "Put your executive summary in a Markdown cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
