{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate branch where Title and Post Text are combined for analysis and classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning/handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# NLP specific libraries\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction import stop_words\n",
    "import re\n",
    "from string import punctuation\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Modeling Libraries\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, auc, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bring in Dataset of Posts scraped from Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./reddit_posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geocaching      1000\n",
       "IWantToLearn    1000\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using regular expressions to remove punctuation in a function\n",
    "def no_punct(string):\n",
    "    return re.sub(\"[.,ðŸ˜¯?ðŸ˜Š!â€™\\\";^+`:*'()-@â€â€œ=>_$&<~%|{}\\[\\]]\", \" \", string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to clean any column or to feed into a word vectorizer as an analyzer parameter\n",
    "def clean_func(column):\n",
    "    \n",
    "    #remove puntuation with punctuation removal function\n",
    "    column = no_punct(column)\n",
    "    \n",
    "    #lowercase\n",
    "    column = column.lower()\n",
    "    \n",
    "    return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that utilizes lemmatizing and a general Regex to remove punctuation\n",
    "\n",
    "def preprocess(text):\n",
    "    # instantiate lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # words only Regex, removes punctuation\n",
    "    text = re.sub(\"[^A-Za-z]\", \" \", text)\n",
    "    \n",
    "    # lemmatize\n",
    "    text = lemmatizer.lemmatize(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning and Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1995, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>1364</td>\n",
       "      <td>1364</td>\n",
       "      <td>I've always procrastinated. I think this is be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>1995</td>\n",
       "      <td>1989</td>\n",
       "      <td>IWTL how to sleep on my back</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <td>1995</td>\n",
       "      <td>2</td>\n",
       "      <td>geocaching</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count unique                                                top freq\n",
       "text       1364   1364  I've always procrastinated. I think this is be...    1\n",
       "title      1995   1989                       IWTL how to sleep on my back    2\n",
       "subreddit  1995      2                                         geocaching  999"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>IWantToLearn</th>\n",
       "      <th>geocaching</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">text</th>\n",
       "      <th>count</th>\n",
       "      <td>890</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>890</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>I've always procrastinated. I think this is be...</td>\n",
       "      <td>There is a missing  Geocache near my house (GC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">title</th>\n",
       "      <th>count</th>\n",
       "      <td>996</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>990</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>I want to learn to speak intellectually.</td>\n",
       "      <td>Favorite Geocaching social media accounts to f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "subreddit                                          IWantToLearn  \\\n",
       "text  count                                                 890   \n",
       "      unique                                                890   \n",
       "      top     I've always procrastinated. I think this is be...   \n",
       "      freq                                                    1   \n",
       "title count                                                 996   \n",
       "      unique                                                990   \n",
       "      top              I want to learn to speak intellectually.   \n",
       "      freq                                                    2   \n",
       "\n",
       "subreddit                                            geocaching  \n",
       "text  count                                                 474  \n",
       "      unique                                                474  \n",
       "      top     There is a missing  Geocache near my house (GC...  \n",
       "      freq                                                    1  \n",
       "title count                                                 999  \n",
       "      unique                                                999  \n",
       "      top     Favorite Geocaching social media accounts to f...  \n",
       "      freq                                                    1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('subreddit').describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examining duplicate Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IWTL how to sleep on my back                                    2\n",
       "IWTL how to meditate                                            2\n",
       "I want to learn how to sing                                     2\n",
       "IWTL how to play the piano                                      2\n",
       "I want to learn to speak intellectually.                        2\n",
       "IWTL how to improve my logical thinking and problem solving.    2\n",
       "IWTL about the electric bikes/cars and how they work?           1\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'].value_counts().sort_values(ascending=False).head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(1979, axis='index', inplace=True)\n",
    "df.drop(1049, axis='index', inplace=True)\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1993, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to see that the two duplicates were removed.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the removal of duplicates, the new dataframe is 1993 posts long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boolean masks to examine geocaching and IWantToLearn subreddits separately.\n",
    "geocaching = df['subreddit'] == 'geocaching'\n",
    "iwtl = df['subreddit'] == 'IWantToLearn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill empty text posts with 'NA'\n",
    "df.fillna('NA', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since I want to predict a binary variable - subreddit `0` for geocaching and `1` for IWantToLearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['subreddit'].map({'geocaching': 0, 'IWantToLearn': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "db045898-1d2d-4af2-8e79-437c4c7546b4"
   },
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Master stopword list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a master stopword list from both stopword lists\n",
    "custom_stopwords = list(set(stopwords.words('english') + list(stop_words.ENGLISH_STOP_WORDS)))\n",
    "\n",
    "# Add 'na' because it indicates an empty text post\n",
    "custom_stopwords.extend(['na'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a stopword list that only takes out 'na'\n",
    "no_na = ['na']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df['title'] + ' ' + df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(corpus, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('model', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'tvec__stop_words': ['english', custom_stopwords],\n",
    "    'tvec__analyzer': ['word', preprocess],\n",
    "    'tvec__max_df': [250, 500, 750],\n",
    "    'tvec__min_df': [1, 2, 3],\n",
    "    'tvec__ngram_range': [(1, 1), (1, 3)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('tvec', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "  ...e,\n",
       "        vocabulary=None)), ('model', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'tvec__stop_words': ['english', ['at', 'everywhere', 'whereby', 'latter', 'otherwise', 'anything', \"hasn't\", 'nowhere', 'detail', 'sixty', 'who', 'not', 'which', 'mightn', 'noone', 'through', 'hers', 'full', 'whereupon', 'he', \"didn't\", 'un', 'former', 'won', 'nobody', 'whenever', 'per',..., 'tvec__max_df': [250, 500, 750], 'tvec__min_df': [1, 2, 3], 'tvec__ngram_range': [(1, 1), (1, 3)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(pipeline, param_grid=params, cv=5)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9812583668005355"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tvec__analyzer': 'word',\n",
       " 'tvec__max_df': 500,\n",
       " 'tvec__min_df': 1,\n",
       " 'tvec__ngram_range': (1, 1),\n",
       " 'tvec__stop_words': 'english'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tvec = TfidfVectorizer(analyzer='word', max_df=500, ngram_range=(1,1), min_df= 1, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the training set\n",
    "best_tv = best_tvec.fit_transform(X_train)\n",
    "\n",
    "# Make into dataframe for modeling\n",
    "X_train_t = pd.DataFrame(best_tv.todense(), columns=best_tvec.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the Testing Text\n",
    "best_tv2 = best_tvec.transform(X_test)\n",
    "\n",
    "# Make into dataframe for modeling\n",
    "X_test_t = pd.DataFrame(best_tv2.todense(), columns=best_tvec.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('model', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'cvec__stop_words': ['english', custom_stopwords],\n",
    "    'cvec__analyzer': ['word', preprocess],\n",
    "    'cvec__max_df': [250, 500, 750],\n",
    "    'cvec__min_df': [1, 2, 3],\n",
    "    'cvec__ngram_range': [(1, 1), (1, 3)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('cvec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor...zer=None, vocabulary=None)), ('model', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'cvec__stop_words': ['english', ['at', 'everywhere', 'whereby', 'latter', 'otherwise', 'anything', \"hasn't\", 'nowhere', 'detail', 'sixty', 'who', 'not', 'which', 'mightn', 'noone', 'through', 'hers', 'full', 'whereupon', 'he', \"didn't\", 'un', 'former', 'won', 'nobody', 'whenever', 'per',..., 'cvec__max_df': [250, 500, 750], 'cvec__min_df': [1, 2, 3], 'cvec__ngram_range': [(1, 1), (1, 3)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2 = GridSearchCV(pipeline, param_grid=params, cv=5)\n",
    "gs2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9886211512717537"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__analyzer': 'word',\n",
       " 'cvec__max_df': 500,\n",
       " 'cvec__min_df': 3,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': 'english'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cvec = CountVectorizer(analyzer='word', max_df=500, ngram_range=(1,1), min_df= 3, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the training set\n",
    "best_c = best_cvec.fit_transform(X_train)\n",
    "\n",
    "# Make into dataframe for modeling\n",
    "X_train_c = pd.DataFrame(best_c.todense(), columns=best_cvec.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the Testing Text\n",
    "best_c2 = best_cvec.transform(X_test)\n",
    "\n",
    "# Make into dataframe for modeling\n",
    "X_test_c = pd.DataFrame(best_c2.todense(), columns=best_cvec.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary of Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = {\n",
    "\n",
    "    # Random Forest\n",
    "    'rf': {\n",
    "        'estimator': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'rf__random_state': [42],\n",
    "            'rf__n_estimators': [9, 10],\n",
    "            #'rf__max_features': [2500, 5000],\n",
    "            #'rf__criterion': ['gini', 'entropy']\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # Logistic Regression\n",
    "    'lr': {\n",
    "        'estimator': LogisticRegression(),\n",
    "        'params': {\n",
    "            'lr__random_state': [42],\n",
    "            #'lr__C': [0.8, 0.9, 1.0],\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # Multinomial Naive-Bayes\n",
    "    'multinb': {\n",
    "        'estimator': MultinomialNB(),\n",
    "        'params': {\n",
    "            #'multinb__alpha': [0.01, 0.1, 0.5]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GrideSearch for Estimator  rf\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    3.1s remaining:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done fitting:  rf\n",
      "--------------------\n",
      "Running GrideSearch for Estimator  lr\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    1.4s remaining:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done fitting:  lr\n",
      "--------------------\n",
      "Running GrideSearch for Estimator  multinb\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    1.6s remaining:    2.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done fitting:  multinb\n",
      "--------------------\n",
      "GridSearch complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.9s finished\n"
     ]
    }
   ],
   "source": [
    "# Make an empty dataframe of fitted models \n",
    "fitted_cvec_models = {}\n",
    "\n",
    "# Loop through models in pipelines, tuning each one with its parameter dictionary\n",
    "for step, config in estimators.items():\n",
    "    pipe = Pipeline(\n",
    "        steps = [\n",
    "            (step, config['estimator'])\n",
    "        ]\n",
    "    )\n",
    "    # Create GridSearch object for each model\n",
    "    model = GridSearchCV(pipe, param_grid=config['params'], cv=5, n_jobs=-1, verbose=1)\n",
    "    print('Running GrideSearch for Estimator ', step)\n",
    "    \n",
    "    # Fit each model and store it in the fitted models dataframe along with score\n",
    "    fitted_cvec_models[step] = model.fit(X_train_c, y_train)\n",
    "    \n",
    "    # Indicators on progress\n",
    "    print('Done fitting: ', step)\n",
    "    print('--------------------')\n",
    "\n",
    "print('GridSearch complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf\n",
      "Training data score:  0.9163319946452476\n",
      "Testing data score:   0.9158316633266533\n",
      "Best Hyperparameters: {'rf__n_estimators': 10, 'rf__random_state': 42}\n",
      "\n",
      "lr\n",
      "Training data score:  0.9404283801874164\n",
      "Testing data score:   0.935871743486974\n",
      "Best Hyperparameters: {'lr__random_state': 42}\n",
      "\n",
      "multinb\n",
      "Training data score:  0.9571619812583668\n",
      "Testing data score:   0.9739478957915831\n",
      "Best Hyperparameters: {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in fitted_cvec_models:\n",
    "    print(model)\n",
    "    print('Training data score: ', fitted_cvec_models[model].best_score_)\n",
    "    best_model = fitted_cvec_models[model].best_estimator_\n",
    "    print('Testing data score:  ', best_model.score(X_test_c, y_test))\n",
    "    print('Best Hyperparameters:', fitted_cvec_models[model].best_params_)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch on TF-IDF corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GrideSearch for Estimator  rf\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    3.9s remaining:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    5.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done fitting:  rf\n",
      "--------------------\n",
      "Running GrideSearch for Estimator  lr\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    1.6s remaining:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done fitting:  lr\n",
      "--------------------\n",
      "Running GrideSearch for Estimator  multinb\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    1.5s remaining:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done fitting:  multinb\n",
      "--------------------\n",
      "GridSearch complete\n"
     ]
    }
   ],
   "source": [
    "# Make an empty dataframe of fitted models \n",
    "fitted_tvec_models = {}\n",
    "\n",
    "# Loop through models in pipelines, tuning each one with its parameter dictionary\n",
    "for step, config in estimators.items():\n",
    "    pipe = Pipeline(\n",
    "        steps = [\n",
    "            (step, config['estimator'])\n",
    "        ]\n",
    "    )\n",
    "    # Create GridSearch object for each model\n",
    "    model = GridSearchCV(pipe, param_grid=config['params'], cv=5, n_jobs=-1, verbose=1)\n",
    "    print('Running GrideSearch for Estimator ', step)\n",
    "    \n",
    "    # Fit each model and store it in the fitted models dataframe along with score\n",
    "    fitted_tvec_models[step] = model.fit(X_train_t, y_train)\n",
    "    \n",
    "    # Indicators on progress\n",
    "    print('Done fitting: ', step)\n",
    "    print('--------------------')\n",
    "\n",
    "print('GridSearch complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf\n",
      "Training data score:  0.9103078982597055\n",
      "Testing data score:   0.9178356713426854\n",
      "Best Hyperparameters: {'rf__n_estimators': 10, 'rf__random_state': 42}\n",
      "\n",
      "lr\n",
      "Training data score:  0.9471218206157965\n",
      "Testing data score:   0.9378757515030061\n",
      "Best Hyperparameters: {'lr__random_state': 42}\n",
      "\n",
      "multinb\n",
      "Training data score:  0.963186077643909\n",
      "Testing data score:   0.9719438877755511\n",
      "Best Hyperparameters: {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in fitted_tvec_models:\n",
    "    print(model)\n",
    "    print('Training data score: ', fitted_tvec_models[model].best_score_)\n",
    "    best_model = fitted_tvec_models[model].best_estimator_\n",
    "    print('Testing data score:  ', best_model.score(X_test_t, y_test))\n",
    "    print('Best Hyperparameters:', fitted_tvec_models[model].best_params_)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
